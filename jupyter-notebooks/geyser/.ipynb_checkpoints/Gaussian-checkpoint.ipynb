{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/zhouc1/notebooks/definexpfam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_median_dist import *\n",
    "from base_density import *\n",
    "from basis_function import *\n",
    "\n",
    "from scorematching_finexpfam import *\n",
    "from evaluate_scorematching_loss import *\n",
    "from negloglik_finexpfam import *\n",
    "from unnormalized_density import *\n",
    "from plot_density_1d import *\n",
    "\n",
    "import scipy \n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # os.chdir('/Users/chenxizhou/Dropbox/Research_Density_Estimation/data_analysis/old_faithful_geyser')\n",
    "# os.chdir('/home/zhouc1/notebooks/definexpfam_results/geyser_eruptions')\n",
    "# true_data = np.load('geyser.npy').astype(np.float64)\n",
    "\n",
    "# # ------------------------------------------------------------------------\n",
    "# # # original data\n",
    "# data_eruptions = deepcopy(true_data[:, 1]).reshape(-1, 1)\n",
    "\n",
    "# # ------------------------------------------------------------------------\n",
    "# # # shift 0.8333333 to different locations\n",
    "# # data_eruptions[data_eruptions == 0.8333333] = 1.379\n",
    "\n",
    "# # ------------------------------------------------------------------------\n",
    "# # add an data point \n",
    "# data_eruptions = np.vstack([data_eruptions, np.array([0.4])])\n",
    "\n",
    "# # ------------------------------------------------------------------------\n",
    "# # # create an isolated obs in the middle \n",
    "# # split_pt = np.median(waiting.flatten())\n",
    "# # add_value = 20. \n",
    "# # waiting[waiting <= split_pt] = waiting[waiting <= split_pt] - add_value\n",
    "# # waiting[waiting > split_pt] = waiting[waiting > split_pt] + add_value\n",
    "# # waiting = np.vstack([waiting.reshape(-1, 1), np.array([split_pt])])\n",
    "# # waiting = waiting[waiting != 108. + add_value].reshape(-1, 1)\n",
    "\n",
    "# # landmarks = data_eruptions\n",
    "# landmarks = np.unique(true_data[:, 1]).reshape(-1, 1)\n",
    "# # landmarks = np.linspace(0.1, 6.9, 20) \n",
    "\n",
    "# xlimit = (0., 7.) \n",
    "# ylimit = (-0.005, 0.97) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/Users/chenxizhou/Dropbox/Research_Density_Estimation/data_analysis/old_faithful_geyser')\n",
    "os.chdir('/home/zhouc1/notebooks/definexpfam_results/geyser_waiting')\n",
    "true_data = np.load('geyser.npy').astype(np.float64)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# # original data\n",
    "data_waiting = deepcopy(true_data[:, 0]).reshape(-1, 1)\n",
    "\n",
    "# # ------------------------------------------------------------------------\n",
    "# # remove 108 \n",
    "# data_waiting = data_waiting[data_waiting != 108.].reshape(-1, 1)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# # flip the data\n",
    "# waiting = (2 * np.median(waiting) - waiting).reshape(-1, 1)\n",
    "\n",
    "# # ------------------------------------------------------------------------\n",
    "# # shift 108 to different locations\n",
    "# data_waiting[data_waiting == 108.] = 135.\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# add an data point \n",
    "data_waiting = np.vstack([data_waiting, np.array([107.]).reshape(-1, 1)])\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# # create an isolated obs in the middle \n",
    "# split_pt = np.median(waiting.flatten())\n",
    "# add_value = 20. \n",
    "# waiting[waiting <= split_pt] = waiting[waiting <= split_pt] - add_value\n",
    "# waiting[waiting > split_pt] = waiting[waiting > split_pt] + add_value\n",
    "# waiting = np.vstack([waiting.reshape(-1, 1), np.array([split_pt])])\n",
    "# waiting = waiting[waiting != 108. + add_value].reshape(-1, 1)\n",
    "\n",
    "landmarks = data_waiting\n",
    "# landmarks = np.unique(data_waiting).reshape(-1, 1)\n",
    "# landmarks = np.unique(true_data[:, 0]).reshape(-1, 1)\n",
    "# landmarks = np.linspace(40., 100., 21).reshape(-1, 1) # np.linspace(0.1, 6.9, 10).reshape(-1, 1)\n",
    "\n",
    "xlimit = (21., 124.)\n",
    "ylimit = (-0.005, 0.0701)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data_waiting.flatten()).describe()\n",
    "# pd.Series(data_eruptions.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(landmarks.flatten())\n",
    "# np.unique(data_waiting.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlimit = xlimit # perturb 115 # (35., 115.) # (41., 115.) # flip \n",
    "# ylimit = ylimit\n",
    "# var_name = 'eruptions'\n",
    "# # use Freedman-Diaconis rule to determine the binwidth \n",
    "# ax = pd.Series(data_eruptions.flatten()).hist(grid = False, figsize = (10, 10), bins = 'fd', density = True) \n",
    "# ax.set_ylim(ylimit)\n",
    "# ax.set_xlim(xlimit)\n",
    "# ax.set_xlabel(var_name)\n",
    "# ax.figure.savefig('hist_eruptions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_dist = data_median_dist(data_waiting.reshape(-1, 1))\n",
    "med_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 2.0\n",
    "basis_function = GaussianBasisFunction(\n",
    "    landmarks = landmarks, \n",
    "    bw = bw)\n",
    "base_density = BasedenGamma(data_waiting, 25.221160023271004, 2.8672107549446633)\n",
    "# waiting base_density.a, base_density.scale # (25.221160023271004, 2.8672107549446633)\n",
    "# eruptions base_density.a, base_density.scale # (7.601343280497627, 0.45528976884425715)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_sm = scorematching_finexpfam_coef(\n",
    "    data = data_waiting, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'add{np.max(data_waiting)}_coef_scorematching_bw={basis_function.bw}_all.npy'\n",
    "# np.save(f'basisfunction_outlier_interaction/{basis_function.basisfunction_name}_basis_function/' + file_name, \n",
    "#        coef_sm)\n",
    "np.save(f'low_density_region/{basis_function.basisfunction_name}_basis_function/' + file_name, \n",
    "       coef_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_domain = xlimit\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)\n",
    "\n",
    "basis_mat = basis_function.basisfunction_eval(x0)\n",
    "y0 = np.matmul(basis_mat.T, coef_sm).flatten()\n",
    "mu = base_density.baseden_eval(x0).flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(x0, np.log(mu) + y0, 'b-')\n",
    "plt.axvline(np.max(data_waiting), 0, 1)\n",
    "#plt.axvline(110, 0, 1)\n",
    "# plt.ylim((-200, -.500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.log(mu) + y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_scorematching_loss(data_eruptions, basis_function, base_density, coef_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_const = 9820.\n",
    "def density_eval_1d_cus(basis_function, base_density, coef):\n",
    "\n",
    "    landmarks = basis_function.landmarks\n",
    "    n_obs = landmarks.shape[0]\n",
    "    \n",
    "    def den(x): \n",
    "\n",
    "        den_val = (base_density.baseden_eval_1d(x) * \n",
    "                   np.exp(- sub_const + np.sum([coef[i] * basis_function.basis_x_1d(landmarks[i])(x)\n",
    "                          for i in range(n_obs)])))\n",
    "        \n",
    "        return den_val\n",
    "\n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_result, _ = scipy.integrate.quad(\n",
    "    density_eval_1d_cus(\n",
    "        basis_function = basis_function, \n",
    "        base_density = base_density, \n",
    "        coef = coef_sm), \n",
    "    a = 0., \n",
    "    b = np.inf)\n",
    "int_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "den_vals = mu * np.exp(y0 - sub_const) / int_result \n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(x0, den_vals, 'b-')\n",
    "plt.xlim(plot_domain) # xlimit)\n",
    "# plt.ylim((-0.01, 20))\n",
    "plt.ylim(ylimit)\n",
    "# plt.axvline(np.min(data_eruptions), 0, 1)\n",
    "plt.axvline(np.max(data_waiting), 0, 1)\n",
    "plt.hist(data_waiting.flatten(), density = True, bins = 'fd', alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'add{107}_denvals_scorematching_bw={basis_function.bw}_all.npy'\n",
    "# np.save(f'basisfunction_outlier_interaction/{basis_function.basisfunction_name}_basis_function/' + file_name, \n",
    "#        den_vals)\n",
    "np.save(f'low_density_region/{basis_function.basisfunction_name}_basis_function/' + file_name, \n",
    "        den_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_list = np.linspace(98., 140., 42 * 2 + 1)\n",
    "outlier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_list = np.linspace(1345., 1355., 11) / 10\n",
    "outlier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_list_bw6 = np.sort(np.unique(outlier_list_bw10))\n",
    "np.save(f'basisfunction_outlier_interaction/Gaussian_basis_function_bw=4.0/outlier_list_bw=4.0.npy', \n",
    "       outlier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_list = [120.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_domain = (21., 155.)\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)\n",
    "landmarks_grid = np.linspace(40., 100., 21).reshape(-1, 1)\n",
    "\n",
    "os.chdir('/home/zhouc1/notebooks/definexpfam_results/geyser_waiting')\n",
    "true_data = np.load('geyser.npy').astype(np.float64)\n",
    "\n",
    "bw = 8.0\n",
    "\n",
    "for i in range(len(outlier_list)): \n",
    "    print('*' * 50)\n",
    "    \n",
    "    outlier = outlier_list[i]\n",
    "    print(f'i = {i}, outlier = {outlier}')\n",
    "    \n",
    "    data_waiting = deepcopy(true_data[:, 0]) # .reshape(-1, 1)\n",
    "    data_waiting[data_waiting == 108.] = outlier\n",
    "    #print(f'max = {np.max(data_waiting)}')\n",
    "    data_waiting = data_waiting.reshape(-1, 1)\n",
    "    # print(pd.Series(data_waiting.flatten()).describe())\n",
    "    \n",
    "    base_density = BasedenGamma(data_waiting, 25.221160023271004, 2.8672107549446633)\n",
    "    basis_function_grid = GaussianBasisFunction(\n",
    "        landmarks = landmarks_grid, # data_eruptions, \n",
    "        bw = bw)\n",
    "    \n",
    "    coef_sm_grid = scorematching_finexpfam_coef(\n",
    "        data = data_waiting, \n",
    "        basis_function = basis_function_grid, \n",
    "        base_density = base_density)\n",
    "    \n",
    "    fig = plt.figure(constrained_layout=False)\n",
    "\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(10)\n",
    "    ncols = 2\n",
    "    nrows = 1\n",
    "    linewidth = 2.0\n",
    "\n",
    "    spec = gridspec.GridSpec(ncols=ncols, nrows=nrows, figure=fig)\n",
    "\n",
    "    ax = fig.add_subplot(spec[0, 0])\n",
    "    \n",
    "    basis_mat_grid = basis_function_grid.basisfunction_eval(x0)\n",
    "    mu = base_density.baseden_eval(x0).flatten()\n",
    "    y0_grid = np.matmul(basis_mat_grid.T, coef_sm_grid).flatten()\n",
    "    denvals_grid = np.log(mu) + y0_grid\n",
    "    \n",
    "    ax.plot(x0, denvals_grid, 'b-')\n",
    "    ax.axvline(outlier, 0, 1)\n",
    "    \n",
    "#     file_name = f'add{np.max(data_waiting)}_logdenvals_scorematching_bw={basis_function_grid.bw}_40_100_21.npy'\n",
    "#     np.save(f'basisfunction_outlier_interaction/{basis_function_grid.basisfunction_name}_basis_function_bw={bw}/' + file_name, \n",
    "#        denvals_grid)\n",
    "    \n",
    "    # basis function at each data point -----------------------\n",
    "    landmarks_data = data_waiting\n",
    "    #print(pd.Series(landmarks_data.flatten()).describe())\n",
    "    basis_function_data = GaussianBasisFunction(\n",
    "        landmarks = landmarks_data, \n",
    "        bw = bw)\n",
    "    \n",
    "    coef_sm_data = scorematching_finexpfam_coef(\n",
    "        data = data_waiting, \n",
    "        basis_function = basis_function_data, \n",
    "        base_density = base_density)\n",
    "    \n",
    "    basis_mat_data = basis_function_data.basisfunction_eval(x0)\n",
    "    mu = base_density.baseden_eval(x0).flatten()\n",
    "    y0_data = np.matmul(basis_mat_data.T, coef_sm_data).flatten()\n",
    "    denvals_data = np.log(mu) + y0_data\n",
    "    \n",
    "#     file_name = f'add{np.max(data_waiting)}_logdenvals_scorematching_bw={basis_function_data.bw}_data.npy'\n",
    "#     np.save(f'basisfunction_outlier_interaction/{basis_function_data.basisfunction_name}_basis_function_bw={bw}/' + file_name, \n",
    "#        denvals_data)\n",
    "    \n",
    "    ax = fig.add_subplot(spec[0, 1])\n",
    "    ax.plot(x0, denvals_data, 'b-')\n",
    "    ax.axvline(outlier, 0, 1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_domain = (21., 155.)\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)\n",
    "landmarks_grid = np.linspace(40., 100., 21).reshape(-1, 1)\n",
    "\n",
    "os.chdir('/home/zhouc1/notebooks/definexpfam_results/geyser_waiting')\n",
    "true_data = np.load('geyser.npy').astype(np.float64)\n",
    "\n",
    "bw = 10.0\n",
    "\n",
    "for i in range(len(outlier_list)): \n",
    "    print('*' * 50)\n",
    "    \n",
    "    outlier = outlier_list[i]\n",
    "    print(f'i = {i}, outlier = {outlier}')\n",
    "    \n",
    "    data_waiting = deepcopy(true_data[:, 0]) # .reshape(-1, 1)\n",
    "    data_waiting[data_waiting == 108.] = outlier\n",
    "    #print(f'max = {np.max(data_waiting)}')\n",
    "    data_waiting = data_waiting.reshape(-1, 1)\n",
    "    # print(pd.Series(data_waiting.flatten()).describe())\n",
    "    \n",
    "    base_density = BasedenGamma(data_waiting, 25.221160023271004, 2.8672107549446633)\n",
    "    basis_function_grid = GaussianBasisFunction(\n",
    "        landmarks = landmarks_grid, # data_eruptions, \n",
    "        bw = bw)\n",
    "    \n",
    "    coef_sm_grid = scorematching_finexpfam_coef(\n",
    "        data = data_waiting, \n",
    "        basis_function = basis_function_grid, \n",
    "        base_density = base_density)\n",
    "    \n",
    "    fig = plt.figure(constrained_layout=False)\n",
    "\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(10)\n",
    "    ncols = 2\n",
    "    nrows = 1\n",
    "    linewidth = 2.0\n",
    "\n",
    "    spec = gridspec.GridSpec(ncols=ncols, nrows=nrows, figure=fig)\n",
    "\n",
    "    ax = fig.add_subplot(spec[0, 0])\n",
    "    \n",
    "    basis_mat_grid = basis_function_grid.basisfunction_eval(x0)\n",
    "    mu = base_density.baseden_eval(x0).flatten()\n",
    "    y0_grid = np.matmul(basis_mat_grid.T, coef_sm_grid).flatten()\n",
    "    denvals_grid = np.log(mu) + y0_grid\n",
    "    \n",
    "    ax.plot(x0, denvals_grid, 'b-')\n",
    "    ax.axvline(outlier, 0, 1)\n",
    "    \n",
    "#     file_name = f'add{np.max(data_waiting)}_logdenvals_scorematching_bw={basis_function_grid.bw}_40_100_21.npy'\n",
    "#     np.save(f'basisfunction_outlier_interaction/{basis_function_grid.basisfunction_name}_basis_function_bw={bw}/' + file_name, \n",
    "#        denvals_grid)\n",
    "    \n",
    "    # basis function at each data point -----------------------\n",
    "    landmarks_data = data_waiting\n",
    "    #print(pd.Series(landmarks_data.flatten()).describe())\n",
    "    basis_function_data = GaussianBasisFunction(\n",
    "        landmarks = landmarks_data, \n",
    "        bw = bw)\n",
    "    \n",
    "    coef_sm_data = scorematching_finexpfam_coef(\n",
    "        data = data_waiting, \n",
    "        basis_function = basis_function_data, \n",
    "        base_density = base_density)\n",
    "    \n",
    "    basis_mat_data = basis_function_data.basisfunction_eval(x0)\n",
    "    mu = base_density.baseden_eval(x0).flatten()\n",
    "    y0_data = np.matmul(basis_mat_data.T, coef_sm_data).flatten()\n",
    "    denvals_data = np.log(mu) + y0_data\n",
    "    \n",
    "#     file_name = f'add{np.max(data_waiting)}_logdenvals_scorematching_bw={basis_function_data.bw}_data.npy'\n",
    "#     np.save(f'basisfunction_outlier_interaction/{basis_function_data.basisfunction_name}_basis_function_bw={bw}/' + file_name, \n",
    "#        denvals_data)\n",
    "    \n",
    "    ax = fig.add_subplot(spec[0, 1])\n",
    "    ax.plot(x0, denvals_data, 'b-')\n",
    "    ax.axvline(outlier, 0, 1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outlier_list = np.linspace(98., 150., 500)\n",
    "# outlier_list = np.arange(98., 125.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "loss_list_outlier = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_domain = xlimit\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)\n",
    "\n",
    "bw = 8.\n",
    "\n",
    "# for i in range(len(bw_list)): \n",
    "for i in range(len(outlier_list)): \n",
    "    if i % 100 == 0: \n",
    "        print('*' * 50)\n",
    "    # bw = bw_list[i]\n",
    "    # print(f'i = {i}, bw = {bw}')\n",
    "    \n",
    "    outlier = outlier_list[i]\n",
    "    if i % 100 == 0: \n",
    "        print(f'i = {i}, outlier = {outlier}')\n",
    "    \n",
    "    data_waiting = deepcopy(true_data[:, 0]) # .reshape(-1, 1)\n",
    "    data_waiting[data_waiting == 108.] = outlier\n",
    "    if i % 100 == 0: \n",
    "        print(f'max = {np.max(data_waiting)}')\n",
    "    data_waiting = data_waiting.reshape(-1, 1)\n",
    "    if i % 100 == 0: \n",
    "        print(pd.Series(data_waiting.flatten()).describe())\n",
    "    \n",
    "    base_density = BasedenGamma(data_waiting, 25.221160023271004, 2.8672107549446633)\n",
    "    basis_function = GaussianBasisFunction(\n",
    "        landmarks = landmarks, # data_eruptions, \n",
    "        bw = bw)\n",
    "    \n",
    "    coef_sm = scorematching_finexpfam_coef(\n",
    "        data = data_waiting, # data_eruptions, # , # \n",
    "        basis_function = basis_function, \n",
    "        base_density = base_density)\n",
    "    \n",
    "#     basis_mat = basis_function.basisfunction_eval(x0)\n",
    "#     mu = base_density.baseden_eval(x0).flatten()\n",
    "#     y0 = np.matmul(basis_mat.T, coef_sm).flatten()\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "#     plt.plot(x0, np.log(mu) + y0, 'b-')\n",
    "#     # plt.vlines(outlier, 0, 1)\n",
    "#     plt.show()\n",
    "    \n",
    "    smloss = evaluate_scorematching_loss(data_waiting, basis_function, base_density, coef_sm)\n",
    "    loss_list.append(smloss)\n",
    "    # print(f'Score Matching Loss = {smloss[2]:.5f}, Squared deriv1 = {smloss[0]:.5f}, deriv2 = {smloss[1]:.5f}.')\n",
    "    \n",
    "    N, d = 1, 1\n",
    "    n_basis = basis_function.landmarks.shape[0]\n",
    "    \n",
    "    DT = basis_function.basisfunction_deriv1(np.array([[outlier]]))\n",
    "    dt_prod_term = sum([np.matmul(DT[:, i].reshape(n_basis, d),\n",
    "                                  DT[:, i].reshape(n_basis, d).T) for i in range(N)])\n",
    "\n",
    "    # compute DT and grad of log mu\n",
    "    # compute the gradient of log mu at data\n",
    "    # each row corresponds to one data point\n",
    "    grad_logmu = np.array([base_density.logbaseden_deriv1(np.array([[outlier]]), j).flatten() for j in range(d)]).T\n",
    "    dt_baseden_term = sum([np.matmul(DT[:, i].reshape(n_basis, d), grad_logmu[[i]].T) for i in range(N)])\n",
    "\n",
    "    output1 = 0.5 * np.matmul(coef_sm.T, np.matmul(dt_prod_term, coef_sm))[0][0] + np.sum(coef_sm.flatten() * dt_baseden_term.flatten())\n",
    "    # np.matmul(coef.T, dt_baseden_term)[0][0]\n",
    "    \n",
    "    # second derivative term \n",
    "    # compute the matrix G, which involves the second derivative\n",
    "    matG = basis_function.basisfunction_deriv2(np.array([[outlier]]))\n",
    "    # print(len(matG))\n",
    "    sum_matG = np.sum(sum([matG[:, i].reshape(n_basis, d) for i in range(N)]), axis=1, keepdims=True)\n",
    "\n",
    "    output2 = np.sum(coef_sm.flatten() * sum_matG.flatten())\n",
    "    # np.matmul(coef.T, sum_matG)[0][0]\n",
    "    \n",
    "    loss_list_outlier.append([output1 / len(data_waiting), output2 / len(data_waiting), (output1 + output2) / len(data_waiting)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv1_part = [item[0] for item in loss_list]\n",
    "deriv2_part = [item[1] for item in loss_list]\n",
    "total_part = [item[2] for item in loss_list]\n",
    "\n",
    "deriv1_part1 = [item[0] for item in loss_list_outlier]\n",
    "deriv2_part1 = [item[1] for item in loss_list_outlier]\n",
    "total_part1 = [item[2] for item in loss_list_outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(outlier_list, deriv1_part1, 'r-', label = '1st derivative part')\n",
    "plt.plot(outlier_list, deriv2_part1, 'b-', label = '2nd derivative part')\n",
    "plt.plot(outlier_list, total_part1, 'k-', label = 'score matching loss values')\n",
    "plt.legend(fontsize = 15)\n",
    "plt.xlabel('outlier', fontsize = 15)\n",
    "plt.ylabel('value', fontsize = 15)\n",
    "plt.tick_params(axis = 'both', labelsize = 15)\n",
    "# plt.savefig('scorematching_value_outlier_combined.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pts_cnt = 4000\n",
    "newx = np.array(outlier_list)\n",
    "plot_ylim = (-0.75, 0.41)\n",
    "\n",
    "fig = plt.figure(constrained_layout=False)\n",
    "\n",
    "fig.set_figheight(32)\n",
    "fig.set_figwidth(16)\n",
    "ncols = 1\n",
    "nrows = 2\n",
    "fontsize = 25\n",
    "linewidth = 2.0\n",
    "\n",
    "spec = gridspec.GridSpec(ncols=ncols, nrows=nrows, figure=fig)\n",
    "\n",
    "ax = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "ax.plot(newx, deriv1_part, color = 'tab:blue', linewidth = linewidth, label = 'sq 1st derivative part')\n",
    "ax.plot(newx, deriv2_part, color = 'tab:red', linewidth = linewidth, label = '2nd derivative part')\n",
    "ax.plot(newx, total_part, color = 'tab:green', linewidth = linewidth, label = 'score matching loss values')\n",
    "ax.legend(fontsize = fontsize, loc = 'lower left')\n",
    "ax.set_ylim(plot_ylim)\n",
    "ax.set_xlabel('location of maximum', fontsize = fontsize)\n",
    "ax.tick_params(axis = 'both', labelsize = fontsize)\n",
    "\n",
    "# info = r\"Add {out}\".format(out = outlier)\n",
    "\n",
    "# ax.text(0.012, 0.988,\n",
    "#         info,\n",
    "#         fontsize = fontsize1,\n",
    "#         multialignment = 'left',\n",
    "#         horizontalalignment = 'left',\n",
    "#         verticalalignment = 'top',\n",
    "#         transform = ax.transAxes,\n",
    "#         bbox = {'facecolor': 'none',\n",
    "#                 'boxstyle': 'Round, pad=0.2'})\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "ax.plot(newx, deriv1_part1, color = 'tab:blue', linewidth = linewidth, label = 'sq 1st derivative part')\n",
    "ax.plot(newx, deriv2_part1, color = 'tab:red', linewidth = linewidth, label = '2nd derivative part')\n",
    "ax.plot(newx, total_part1, color = 'tab:green', linewidth = linewidth, label = 'score matching loss values')\n",
    "ax.legend(fontsize = fontsize, loc = 'lower left')\n",
    "ax.set_xlabel('location of maximum', fontsize = fontsize)\n",
    "ax.set_ylim(plot_ylim)\n",
    "ax.tick_params(axis = 'both', labelsize = fontsize)\n",
    "\n",
    "plt.savefig('scorematching_value_outlier_combined_vertical.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_denvals_scorematching_bw={basis_function.bw}_0.1_6.9_20.npy'\n",
    "np.save(f'{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "        den_vals)\n",
    "\n",
    "# np.save(f'{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "#         den_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_denvals_scorematching_bw=0.3.npy'\n",
    "yy0 = np.load(f'{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(x0, yy0/1e105, 'b-')\n",
    "plt.xlim(xlimit)\n",
    "plt.ylim(ylimit)\n",
    "# plt.vlines(x = 75., ymin = -1, ymax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_denvals_scorematching_bw=0.3.npy'\n",
    "np.save(f'{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, yy0/1e105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchmc_params = batch_montecarlo_params(\n",
    "    mc_batch_size = 1000, \n",
    "    mc_tol = 1e-2)\n",
    "\n",
    "nll_algo_params = negloglik_optalgoparams(\n",
    "    start_pt = np.zeros((data_eruptions.shape[0], 1)), \n",
    "    step_size = 0.03, \n",
    "    max_iter = 100, \n",
    "    rel_tol = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "now1 = datetime.now()\n",
    "\n",
    "coef_lik = negloglik_finexpfam_coef(\n",
    "    data = data_eruptions, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density, \n",
    "    optalgo_params = nll_algo_params, \n",
    "    batchmc_params = batchmc_params,\n",
    "    batch_mc = True, \n",
    "    batch_mc_se = False, \n",
    "    print_error = True)\n",
    "now2 = datetime.now()\n",
    "print(now1, now2)\n",
    "print(now2 - now1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_coef_likelihood_bw={basis_function.bw}.npy'\n",
    "np.save(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name, \n",
    "        coef_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_domain = xlimit\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_mat = basis_function.basisfunction_eval(x0)\n",
    "y0 = np.matmul(basis_mat.T, coef_lik).flatten()\n",
    "mu = base_density.baseden_eval(x0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(x0, np.log(mu) + y0, 'b-')\n",
    "#plt.ylim((4e6, 4.3e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_coef_likelihood_bw={basis_function.bw}.npy'\n",
    "coef_lik = np.load(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm = UnnormalizedDensityFinExpFam(\n",
    "    data = data_eruptions, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density, \n",
    "    coef = coef_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_fun = unnorm.density_eval\n",
    "unnorm_fun_int = unnorm.density_eval_1d\n",
    "x0_cand = np.linspace(xlimit[0], xlimit[1], num=4000).reshape(-1, 1)\n",
    "plot_val = unnorm_fun(x0_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_const, _ = integrate.nquad(unnorm_fun_int, base_density.domain, opts={'limit': 100})\n",
    "norm_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_coef_likelihood_bw=0.4.npy'\n",
    "coef_lik = np.load(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = plot_density_1d_params(x_limit = xlimit, y_limit = ylimit, plot_pts_cnt=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denvals = plot_density_1d(\n",
    "    data = data_eruptions, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density, \n",
    "    coef = coef_lik, \n",
    "    normalizing = True, \n",
    "    method = 'likelihood', \n",
    "    x_label = 'waiting',\n",
    "    plot_kwargs = plot_params, \n",
    "    save_plot = False, \n",
    "    save_dir = None, \n",
    "    save_filename = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_denvals_likelihood_bw={basis_function.bw}.npy'\n",
    "np.save(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name, \n",
    "        denvals['den_vals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
