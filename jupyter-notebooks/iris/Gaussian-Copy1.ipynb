{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/zhouc1/notebooks/definexpfam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_median_dist import *\n",
    "from base_density import *\n",
    "from basis_function import *\n",
    "\n",
    "from scorematching_finexpfam import *\n",
    "from evaluate_scorematching_loss import *\n",
    "from negloglik_finexpfam import *\n",
    "from unnormalized_density import *\n",
    "from plot_density_1d import *\n",
    "\n",
    "import scipy \n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorematching_finexpfam_coef11(data, basis_function, base_density):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the solution to minimizing the score matching loss function\n",
    "    in finite-dimensional exponential family.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        The array of observations whose density function is to be estimated.\n",
    "\n",
    "    basis_function : kernel_function object\n",
    "        The basis function of the canonical statistic used to estimate the probability density function.\n",
    "        __type__ must be 'basis_function'.\n",
    "\n",
    "    base_density : base_density object\n",
    "        The base density function used to estimate the probability density function.\n",
    "        __type__ must be 'base_density'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of coefficients for the natural parameter in the score matching density estimate.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    N, d = data.shape\n",
    "    n_basis = basis_function.landmarks.shape[0]\n",
    "\n",
    "    # compute DT(X_i) DT(X_i)^\\top\n",
    "    DT = basis_function.basisfunction_deriv1(data)\n",
    "    dt_prod_term = sum([np.matmul(DT[:, i].reshape(n_basis, d),\n",
    "                                  DT[:, i].reshape(n_basis, d).T) for i in range(N)])\n",
    "\n",
    "    # compute the matrix G, which involves the second derivative\n",
    "    matG = basis_function.basisfunction_deriv2(data)\n",
    "    sum_matG = np.sum(sum([matG[:, i].reshape(n_basis, d) for i in range(N)]), axis=1, keepdims=True)\n",
    "\n",
    "    # compute DT and grad of log mu\n",
    "    # compute the gradient of log mu at data\n",
    "    # each row corresponds to one data point\n",
    "    grad_logmu = np.array([base_density.logbaseden_deriv1(data, j).flatten() for j in range(d)]).T\n",
    "    dt_baseden_term = sum([np.matmul(DT[:, i].reshape(n_basis, d), grad_logmu[[i]].T) for i in range(N)])\n",
    "\n",
    "    b_term = sum_matG + dt_baseden_term\n",
    "\n",
    "    coef = -np.linalg.lstsq(dt_prod_term, b_term, rcond=None)[0]\n",
    "\n",
    "    return dt_prod_term, b_term, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/Users/chenxizhou/Dropbox/Research_Density_Estimation/data_analysis/old_faithful_geyser')\n",
    "os.chdir('/home/zhouc1/notebooks/definexpfam_results/iris')\n",
    "true_data = pd.read_csv('iris.csv')# .astype(np.float64)\n",
    "var_name = 'Petal_Width'\n",
    "df = deepcopy(true_data[var_name]).to_numpy().reshape(-1, 1)\n",
    "xlimit = (0., 4.)\n",
    "ylimit = (-0.005, 1.42)\n",
    "\n",
    "# sepal_length = deepcopy(true_data['Sepal_Length']).to_numpy().reshape(-1, 1) # (2., 10.), (-0.005, 0.99)\n",
    "# sepal_width = deepcopy(true_data['Sepal_Width']).to_numpy().reshape(-1, 1) # (0., 6.), (-0.005, 0.99)\n",
    "# petal_length = deepcopy(true_data['Petal_Length']).to_numpy().reshape(-1, 1) # (0.5, 9.5), (-0.005, 1.42)\n",
    "# petal_width = deepcopy(true_data['Petal_Width']).to_numpy().reshape(-1, 1) # (0., 4.), (-0.005, 1.42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use Freedman-Diaconis rule to determine the binwidth \n",
    "# ax = pd.Series(df.flatten()).hist(grid = False, figsize = (10, 10), bins = 'fd', density = True) \n",
    "# ax.set_ylim(ylimit)\n",
    "# ax.set_xlim(xlimit)\n",
    "# ax.set_xlabel(var_name)\n",
    "# # ax.figure.savefig('hist_eruptions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6,\n",
       "       1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# # add an data point \n",
    "# df = np.vstack([df, np.array([7.287])])\n",
    "\n",
    "# df[df == 2.0] = 1.885\n",
    "\n",
    "landmarks = np.unique(deepcopy(true_data[var_name])).reshape(-1, 1)\n",
    "# landmarks = np.linspace(0.1, 6.9, 10).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(df.flatten()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks.flatten()\n",
    "# np.unique(data_waiting.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# med_dist = data_median_dist(df.reshape(-1, 1))\n",
    "# med_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 1.0\n",
    "basis_function = GaussianBasisFunction(\n",
    "    landmarks = landmarks, \n",
    "    bw = bw)\n",
    "base_density = BasedenGamma(df, 3.5170581590028753, 1.068506641091609)\n",
    "base_density.a, base_density.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepal_length, 49.351702439900336, 0.11818134011138696\n",
    "# sepal_width, 49.651897882066784, 0.06157535690972203\n",
    "# petal_length, 3.5170581590028753, 1.068506641091609\n",
    "# petal_width, 1.5578209222227564, 0.7698788199750717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_sm = scorematching_finexpfam_coef(\n",
    "    data = df, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'add{np.max(df)}_coef_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "# f'shift2.0to{np.min(df)}_coef_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "# f'original_coef_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "\n",
    "np.save(f'{var_name}/{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "       coef_sm)\n",
    "# # np.save(f'bandwidth_effect/{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "# #        coef_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_domain = xlimit\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)\n",
    "\n",
    "basis_mat = basis_function.basisfunction_eval(x0)\n",
    "y0 = np.matmul(basis_mat.T, coef_sm).flatten()\n",
    "mu = base_density.baseden_eval(x0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(x0, np.log(mu) + y0, 'b-')\n",
    "# plt.axvline(108., 0, 1)\n",
    "#plt.ylim((5.6e5, 5.7e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_const = 3400.\n",
    "def density_eval_1d_cus(basis_function, base_density, coef):\n",
    "\n",
    "    landmarks = basis_function.landmarks\n",
    "    n_obs = landmarks.shape[0]\n",
    "    \n",
    "    def den(x): \n",
    "\n",
    "        den_val = (base_density.baseden_eval_1d(x) * \n",
    "                   np.exp(- sub_const + np.sum([coef[i] * basis_function.basis_x_1d(landmarks[i])(x)\n",
    "                          for i in range(n_obs)])))\n",
    "        \n",
    "        return den_val\n",
    "\n",
    "    return den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_result, _ = scipy.integrate.quad(\n",
    "    density_eval_1d_cus(\n",
    "        basis_function = basis_function, \n",
    "        base_density = base_density, \n",
    "        coef = coef_sm), \n",
    "    a = 0., \n",
    "    b = np.inf, \n",
    "limit=1000)\n",
    "int_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "den_vals = mu * np.exp(y0 - sub_const) / int_result \n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(x0, den_vals, 'b-')\n",
    "plt.xlim(plot_domain) # xlimit)\n",
    "#plt.ylim((-0.01, 20))\n",
    "plt.ylim(ylimit)\n",
    "#plt.axvline(115., 0, 1)\n",
    "# plt.vlines(x = 75., ymin = -1, ymax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'add{np.max(df)}_denvals_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "# f'shift2.0to{np.min(df)}_denvals_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "# f'original_denvals_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "\n",
    "np.save(f'{var_name}/{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "        den_vals)\n",
    "# np.save(f'{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "#         den_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bw_list = np.linspace(14.5513, 14.5514, 100)\n",
    "outlier_list = np.arange(2010, 2020) / 1000.\n",
    "outlier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_domain = xlimit\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)\n",
    "\n",
    "bw = 0.6\n",
    "var_name = 'Sepal_Width'\n",
    "\n",
    "# for i in range(len(bw_list)): \n",
    "for i in range(len(outlier_list)): \n",
    "    print('*' * 50)\n",
    "    # bw = bw_list[i]\n",
    "    # print(f'i = {i}, bw = {bw}')\n",
    "    \n",
    "    outlier = outlier_list[i]\n",
    "    print(f'i = {i}, outlier = {outlier}')\n",
    "    \n",
    "    data_frame = deepcopy(true_data[var_name].to_numpy()) # .reshape(-1, 1)\n",
    "    data_frame = np.append(data_frame, outlier)\n",
    "    print(f'max = {np.max(data_frame)}')\n",
    "    data_frame = data_frame.reshape(-1, 1)\n",
    "    print(pd.Series(data_frame.flatten()).describe())\n",
    "    \n",
    "    base_density = BasedenGamma(data_frame, 1.5578209222227564, 0.7698788199750717)\n",
    "    basis_function = GaussianBasisFunction(\n",
    "        landmarks = landmarks, # data_eruptions, \n",
    "        bw = bw)\n",
    "    \n",
    "    coef_sm = scorematching_finexpfam_coef(\n",
    "        data = data_frame, \n",
    "        basis_function = basis_function, \n",
    "        base_density = base_density)\n",
    "    \n",
    "    file_name = f'add{np.max(data_frame)}_coef_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "# f'shift2.0to{np.min(df)}_coef_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "# f'original_coef_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "\n",
    "    np.save(f'{var_name}/{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "       coef_sm)\n",
    "    \n",
    "    basis_mat = basis_function.basisfunction_eval(x0)\n",
    "    mu = base_density.baseden_eval(x0).flatten()\n",
    "    y0 = np.matmul(basis_mat.T, coef_sm).flatten()\n",
    "    \n",
    "    sub_const = 20000.\n",
    "\n",
    "    def density_eval_1d_cus(basis_function, base_density, coef):\n",
    "\n",
    "        landmarks = basis_function.landmarks\n",
    "        n_obs = landmarks.shape[0]\n",
    "\n",
    "        def den(x): \n",
    "\n",
    "            den_val = (base_density.baseden_eval_1d(x) * \n",
    "                       np.exp(- sub_const + np.sum([coef[i] * basis_function.basis_x_1d(landmarks[i])(x)\n",
    "                              for i in range(n_obs)])))\n",
    "\n",
    "            return den_val\n",
    "\n",
    "        return den\n",
    "\n",
    "\n",
    "    int_result, _ = scipy.integrate.quad(\n",
    "    density_eval_1d_cus(\n",
    "        basis_function = basis_function, \n",
    "        base_density = base_density, \n",
    "        coef = coef_sm), \n",
    "    a = 0., \n",
    "    b = np.inf, \n",
    "    limit=1000)\n",
    "    \n",
    "    plt.figure(figsize=(7, 7))\n",
    "    den_vals = mu * np.exp(y0 - sub_const) / int_result \n",
    "    plt.plot(x0, den_vals, 'b-')\n",
    "    plt.xlim(plot_domain) # xlimit)\n",
    "    #plt.ylim((-0.01, 20))\n",
    "    plt.ylim(ylimit)\n",
    "    plt.vlines(outlier, 0, 1)\n",
    "    plt.show()\n",
    "    \n",
    "    file_name = f'shift2.0to{np.min(data_frame)}_denvals_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "    # f'shift2.0to{np.min(df)}_denvals_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "    # f'original_denvals_scorematching_bw={basis_function.bw}_unique.npy'\n",
    "\n",
    "    np.save(f'{var_name}/{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, \n",
    "        den_vals)\n",
    "    \n",
    "#     smloss = evaluate_scorematching_loss(data_frame, basis_function, base_density, coef_sm)\n",
    "#     loss_list.append(smloss)\n",
    "#     print(f'Score Matching Loss = {smloss[2]:.5f}, Squared deriv1 = {smloss[0]:.5f}, deriv2 = {smloss[1]:.5f}.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_denvals = np.log(mu) + y0\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.plot(x0, log_denvals, 'b-')\n",
    "# plt.axvline(108., 0, 1)\n",
    "# plt.ylim((0.79e5, 0.81e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'shift108to99_logdenvals_scorematching_bw={basis_function.bw}_35_110_16.npy'\n",
    "np.save(f'dataloc_effect/{basis_function.basisfunction_name}_basis_function/' + file_name, \n",
    "        log_denvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis_function.basisfunction_name, basis_function.bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_denvals_scorematching_bw=0.3.npy'\n",
    "yy0 = np.load(f'{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(x0, yy0/1e105, 'b-')\n",
    "plt.xlim(xlimit)\n",
    "plt.ylim(ylimit)\n",
    "# plt.vlines(x = 75., ymin = -1, ymax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_denvals_scorematching_bw=0.3.npy'\n",
    "np.save(f'{basis_function.basisfunction_name}_basis_function/scorematching/' + file_name, yy0/1e105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchmc_params = batch_montecarlo_params(\n",
    "    mc_batch_size = 1000, \n",
    "    mc_tol = 1e-2)\n",
    "\n",
    "nll_algo_params = negloglik_optalgoparams(\n",
    "    start_pt = np.zeros((data_eruptions.shape[0], 1)), \n",
    "    step_size = 0.03, \n",
    "    max_iter = 100, \n",
    "    rel_tol = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "now1 = datetime.now()\n",
    "\n",
    "coef_lik = negloglik_finexpfam_coef(\n",
    "    data = data_eruptions, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density, \n",
    "    optalgo_params = nll_algo_params, \n",
    "    batchmc_params = batchmc_params,\n",
    "    batch_mc = True, \n",
    "    batch_mc_se = False, \n",
    "    print_error = True)\n",
    "now2 = datetime.now()\n",
    "print(now1, now2)\n",
    "print(now2 - now1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_coef_likelihood_bw={basis_function.bw}.npy'\n",
    "np.save(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name, \n",
    "        coef_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_domain = xlimit\n",
    "plot_pts_cnt = 4000\n",
    "x0 = np.linspace(plot_domain[0], plot_domain[1], plot_pts_cnt).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_mat = basis_function.basisfunction_eval(x0)\n",
    "y0 = np.matmul(basis_mat.T, coef_lik).flatten()\n",
    "mu = base_density.baseden_eval(x0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(x0, np.log(mu) + y0, 'b-')\n",
    "#plt.ylim((4e6, 4.3e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_coef_likelihood_bw={basis_function.bw}.npy'\n",
    "coef_lik = np.load(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm = UnnormalizedDensityFinExpFam(\n",
    "    data = data_eruptions, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density, \n",
    "    coef = coef_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_fun = unnorm.density_eval\n",
    "unnorm_fun_int = unnorm.density_eval_1d\n",
    "x0_cand = np.linspace(xlimit[0], xlimit[1], num=4000).reshape(-1, 1)\n",
    "plot_val = unnorm_fun(x0_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_const, _ = integrate.nquad(unnorm_fun_int, base_density.domain, opts={'limit': 100})\n",
    "norm_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_coef_likelihood_bw=0.4.npy'\n",
    "coef_lik = np.load(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = plot_density_1d_params(x_limit = xlimit, y_limit = ylimit, plot_pts_cnt=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denvals = plot_density_1d(\n",
    "    data = data_eruptions, \n",
    "    basis_function = basis_function, \n",
    "    base_density = base_density, \n",
    "    coef = coef_lik, \n",
    "    normalizing = True, \n",
    "    method = 'likelihood', \n",
    "    x_label = 'waiting',\n",
    "    plot_kwargs = plot_params, \n",
    "    save_plot = False, \n",
    "    save_dir = None, \n",
    "    save_filename = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f'original_denvals_likelihood_bw={basis_function.bw}.npy'\n",
    "np.save(f'{basis_function.basisfunction_name}_basis_function/likelihood/' + file_name, \n",
    "        denvals['den_vals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
